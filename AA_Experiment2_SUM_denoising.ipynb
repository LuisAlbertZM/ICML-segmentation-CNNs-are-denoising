{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.dataloaders import dataLoaderDenoising\n",
    "\n",
    "    \n",
    "dataset = \"BRATSmini5_train.h5\"\n",
    "# Getting the patient numbers\n",
    "iDlist = []\n",
    "with h5py.File(dataset, 'r' ) as f:\n",
    "    keys = list(f.keys())\n",
    "    for k in keys:\n",
    "        # First split is patient iD\n",
    "        iD = k.split(\"_\")[0]\n",
    "        if iD in iDlist:\n",
    "            pass\n",
    "        else:\n",
    "            iDlist.append(iD)\n",
    "\n",
    "Npat = len(iDlist)\n",
    "trai_list = iDlist[0:Npat//3]\n",
    "vali_list = iDlist[Npat//3:2*Npat//3]\n",
    "test_list = iDlist[2*Npat//3:-1]\n",
    "\n",
    "\n",
    "trai_data = dataLoaderDenoising(dataset, trai_list)\n",
    "vali_data = dataLoaderDenoising(dataset, vali_list)\n",
    "test_data = dataLoaderDenoising(dataset, test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net parameters\n",
    "wf = 8\n",
    "depth = 4\n",
    "in_chans= 1\n",
    "\n",
    "# optimization\n",
    "bs = 8\n",
    "ilr = 3.5e-4\n",
    "epo = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_trai(cnn,x, y):\n",
    "    return( F.l1_loss(y, cnn(x, thr=1)[0]) )\n",
    "\n",
    "def loss_vali(cnn,x, y):\n",
    "    return( F.l1_loss(y, cnn(x, thr=1)[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ,LR: 0.00035, Train Loss: 0.01225, Val Loss: 0.01217, Saved: 1\n",
      "Epoch: 1 ,LR: 0.00035, Train Loss: 0.01069, Val Loss: 0.01054, Saved: 1\n",
      "Epoch: 2 ,LR: 0.00035, Train Loss: 0.01042, Val Loss: 0.01027, Saved: 1\n",
      "Epoch: 3 ,LR: 0.00035, Train Loss: 0.00978, Val Loss: 0.00959, Saved: 1\n",
      "Epoch: 4 ,LR: 0.00035, Train Loss: 0.00997, Val Loss: 0.00980, Saved: 1\n",
      "Epoch: 5 ,LR: 0.00035, Train Loss: 0.00946, Val Loss: 0.00926, Saved: 1\n",
      "Epoch: 6 ,LR: 0.00034, Train Loss: 0.00959, Val Loss: 0.00938, Saved: 1\n",
      "Epoch: 7 ,LR: 0.00034, Train Loss: 0.00950, Val Loss: 0.00931, Saved: 1\n",
      "Epoch: 8 ,LR: 0.00034, Train Loss: 0.00924, Val Loss: 0.00902, Saved: 1\n",
      "Epoch: 9 ,LR: 0.00034, Train Loss: 0.00923, Val Loss: 0.00902, Saved: 1\n",
      "Epoch: 10 ,LR: 0.00034, Train Loss: 0.00925, Val Loss: 0.00904, Saved: 1\n",
      "Epoch: 11 ,LR: 0.00034, Train Loss: 0.00908, Val Loss: 0.00887, Saved: 1\n",
      "Epoch: 12 ,LR: 0.00034, Train Loss: 0.00920, Val Loss: 0.00900, Saved: 1\n",
      "Epoch: 13 ,LR: 0.00034, Train Loss: 0.00902, Val Loss: 0.00879, Saved: 1\n",
      "Epoch: 14 ,LR: 0.00033, Train Loss: 0.00903, Val Loss: 0.00880, Saved: 1\n",
      "Epoch: 15 ,LR: 0.00033, Train Loss: 0.00898, Val Loss: 0.00877, Saved: 1\n",
      "Epoch: 16 ,LR: 0.00033, Train Loss: 0.00929, Val Loss: 0.00907, Saved: 1\n",
      "Epoch: 17 ,LR: 0.00033, Train Loss: 0.00897, Val Loss: 0.00876, Saved: 1\n",
      "Epoch: 18 ,LR: 0.00033, Train Loss: 0.00891, Val Loss: 0.00871, Saved: 1\n",
      "Epoch: 19 ,LR: 0.00033, Train Loss: 0.00893, Val Loss: 0.00869, Saved: 1\n",
      "Epoch: 20 ,LR: 0.00033, Train Loss: 0.00889, Val Loss: 0.00869, Saved: 1\n",
      "Epoch: 21 ,LR: 0.00033, Train Loss: 0.00885, Val Loss: 0.00865, Saved: 1\n",
      "Epoch: 22 ,LR: 0.00033, Train Loss: 0.00898, Val Loss: 0.00876, Saved: 1\n",
      "Epoch: 23 ,LR: 0.00032, Train Loss: 0.00907, Val Loss: 0.00885, Saved: 1\n",
      "Epoch: 24 ,LR: 0.00032, Train Loss: 0.00894, Val Loss: 0.00872, Saved: 1\n",
      "Epoch: 25 ,LR: 0.00032, Train Loss: 0.00922, Val Loss: 0.00901, Saved: 1\n",
      "Epoch: 26 ,LR: 0.00032, Train Loss: 0.00885, Val Loss: 0.00864, Saved: 1\n",
      "Epoch: 27 ,LR: 0.00032, Train Loss: 0.00883, Val Loss: 0.00862, Saved: 1\n",
      "Epoch: 28 ,LR: 0.00032, Train Loss: 0.00888, Val Loss: 0.00865, Saved: 1\n",
      "Epoch: 29 ,LR: 0.00032, Train Loss: 0.00882, Val Loss: 0.00859, Saved: 1\n",
      "Epoch: 30 ,LR: 0.00032, Train Loss: 0.00886, Val Loss: 0.00865, Saved: 1\n",
      "Epoch: 31 ,LR: 0.00032, Train Loss: 0.00912, Val Loss: 0.00894, Saved: 1\n",
      "Epoch: 32 ,LR: 0.00031, Train Loss: 0.00894, Val Loss: 0.00872, Saved: 1\n",
      "Epoch: 33 ,LR: 0.00031, Train Loss: 0.00885, Val Loss: 0.00864, Saved: 1\n",
      "Epoch: 34 ,LR: 0.00031, Train Loss: 0.00879, Val Loss: 0.00856, Saved: 1\n",
      "Epoch: 35 ,LR: 0.00031, Train Loss: 0.00879, Val Loss: 0.00858, Saved: 1\n",
      "Epoch: 36 ,LR: 0.00031, Train Loss: 0.00878, Val Loss: 0.00857, Saved: 1\n",
      "Epoch: 37 ,LR: 0.00031, Train Loss: 0.00876, Val Loss: 0.00855, Saved: 1\n",
      "Epoch: 38 ,LR: 0.00031, Train Loss: 0.00875, Val Loss: 0.00853, Saved: 1\n",
      "Epoch: 39 ,LR: 0.00031, Train Loss: 0.00877, Val Loss: 0.00854, Saved: 1\n",
      "Epoch: 40 ,LR: 0.00030, Train Loss: 0.00876, Val Loss: 0.00854, Saved: 1\n",
      "Epoch: 41 ,LR: 0.00030, Train Loss: 0.00877, Val Loss: 0.00857, Saved: 1\n",
      "Epoch: 42 ,LR: 0.00030, Train Loss: 0.00874, Val Loss: 0.00853, Saved: 1\n",
      "Epoch: 43 ,LR: 0.00030, Train Loss: 0.00879, Val Loss: 0.00859, Saved: 1\n",
      "Epoch: 44 ,LR: 0.00030, Train Loss: 0.00881, Val Loss: 0.00858, Saved: 1\n",
      "Epoch: 45 ,LR: 0.00030, Train Loss: 0.00876, Val Loss: 0.00854, Saved: 1\n",
      "Epoch: 46 ,LR: 0.00030, Train Loss: 0.00874, Val Loss: 0.00854, Saved: 1\n",
      "Epoch: 47 ,LR: 0.00030, Train Loss: 0.00871, Val Loss: 0.00849, Saved: 1\n",
      "Epoch: 48 ,LR: 0.00030, Train Loss: 0.00875, Val Loss: 0.00854, Saved: 1\n",
      "Epoch: 49 ,LR: 0.00029, Train Loss: 0.00892, Val Loss: 0.00872, Saved: 1\n",
      "Epoch: 50 ,LR: 0.00029, Train Loss: 0.00874, Val Loss: 0.00852, Saved: 1\n",
      "Epoch: 51 ,LR: 0.00029, Train Loss: 0.00870, Val Loss: 0.00849, Saved: 1\n",
      "Epoch: 52 ,LR: 0.00029, Train Loss: 0.00869, Val Loss: 0.00848, Saved: 1\n",
      "Epoch: 53 ,LR: 0.00029, Train Loss: 0.00869, Val Loss: 0.00848, Saved: 1\n",
      "Epoch: 54 ,LR: 0.00029, Train Loss: 0.00868, Val Loss: 0.00846, Saved: 1\n",
      "Epoch: 55 ,LR: 0.00029, Train Loss: 0.00869, Val Loss: 0.00847, Saved: 1\n",
      "Epoch: 56 ,LR: 0.00029, Train Loss: 0.00872, Val Loss: 0.00851, Saved: 1\n",
      "Epoch: 57 ,LR: 0.00028, Train Loss: 0.00878, Val Loss: 0.00856, Saved: 1\n",
      "Epoch: 58 ,LR: 0.00028, Train Loss: 0.00932, Val Loss: 0.00915, Saved: 1\n",
      "Epoch: 59 ,LR: 0.00028, Train Loss: 0.00885, Val Loss: 0.00866, Saved: 1\n",
      "Epoch: 60 ,LR: 0.00028, Train Loss: 0.00867, Val Loss: 0.00846, Saved: 1\n",
      "Epoch: 61 ,LR: 0.00028, Train Loss: 0.00866, Val Loss: 0.00845, Saved: 1\n",
      "Epoch: 62 ,LR: 0.00028, Train Loss: 0.00876, Val Loss: 0.00856, Saved: 1\n",
      "Epoch: 63 ,LR: 0.00028, Train Loss: 0.00874, Val Loss: 0.00854, Saved: 1\n",
      "Epoch: 64 ,LR: 0.00028, Train Loss: 0.00869, Val Loss: 0.00846, Saved: 1\n",
      "Epoch: 65 ,LR: 0.00028, Train Loss: 0.00870, Val Loss: 0.00848, Saved: 1\n",
      "Epoch: 66 ,LR: 0.00027, Train Loss: 0.00871, Val Loss: 0.00848, Saved: 1\n",
      "Epoch: 67 ,LR: 0.00027, Train Loss: 0.00868, Val Loss: 0.00847, Saved: 1\n",
      "Epoch: 68 ,LR: 0.00027, Train Loss: 0.00873, Val Loss: 0.00852, Saved: 1\n",
      "Epoch: 69 ,LR: 0.00027, Train Loss: 0.00873, Val Loss: 0.00851, Saved: 1\n",
      "Epoch: 70 ,LR: 0.00027, Train Loss: 0.00879, Val Loss: 0.00859, Saved: 1\n",
      "Epoch: 71 ,LR: 0.00027, Train Loss: 0.00862, Val Loss: 0.00842, Saved: 1\n",
      "Epoch: 72 ,LR: 0.00027, Train Loss: 0.00864, Val Loss: 0.00841, Saved: 1\n",
      "Epoch: 73 ,LR: 0.00027, Train Loss: 0.00875, Val Loss: 0.00855, Saved: 1\n",
      "Epoch: 74 ,LR: 0.00026, Train Loss: 0.00867, Val Loss: 0.00845, Saved: 1\n",
      "Epoch: 75 ,LR: 0.00026, Train Loss: 0.00863, Val Loss: 0.00841, Saved: 1\n",
      "Epoch: 76 ,LR: 0.00026, Train Loss: 0.00862, Val Loss: 0.00841, Saved: 1\n",
      "Epoch: 77 ,LR: 0.00026, Train Loss: 0.00865, Val Loss: 0.00841, Saved: 1\n",
      "Epoch: 78 ,LR: 0.00026, Train Loss: 0.00861, Val Loss: 0.00839, Saved: 1\n",
      "Epoch: 79 ,LR: 0.00026, Train Loss: 0.00864, Val Loss: 0.00841, Saved: 1\n",
      "Epoch: 80 ,LR: 0.00026, Train Loss: 0.00860, Val Loss: 0.00840, Saved: 1\n",
      "Epoch: 81 ,LR: 0.00026, Train Loss: 0.00862, Val Loss: 0.00842, Saved: 1\n",
      "Epoch: 82 ,LR: 0.00026, Train Loss: 0.00878, Val Loss: 0.00859, Saved: 1\n",
      "Epoch: 83 ,LR: 0.00025, Train Loss: 0.00863, Val Loss: 0.00843, Saved: 1\n",
      "Epoch: 84 ,LR: 0.00025, Train Loss: 0.00865, Val Loss: 0.00844, Saved: 1\n",
      "Epoch: 85 ,LR: 0.00025, Train Loss: 0.00862, Val Loss: 0.00842, Saved: 1\n",
      "Epoch: 86 ,LR: 0.00025, Train Loss: 0.00859, Val Loss: 0.00838, Saved: 1\n",
      "Epoch: 87 ,LR: 0.00025, Train Loss: 0.00861, Val Loss: 0.00840, Saved: 1\n",
      "Epoch: 88 ,LR: 0.00025, Train Loss: 0.00888, Val Loss: 0.00868, Saved: 1\n",
      "Epoch: 89 ,LR: 0.00025, Train Loss: 0.00857, Val Loss: 0.00836, Saved: 1\n",
      "Epoch: 90 ,LR: 0.00025, Train Loss: 0.00859, Val Loss: 0.00838, Saved: 1\n",
      "Epoch: 91 ,LR: 0.00024, Train Loss: 0.00858, Val Loss: 0.00839, Saved: 1\n",
      "Epoch: 92 ,LR: 0.00024, Train Loss: 0.00858, Val Loss: 0.00839, Saved: 1\n",
      "Epoch: 93 ,LR: 0.00024, Train Loss: 0.00862, Val Loss: 0.00841, Saved: 1\n",
      "Epoch: 94 ,LR: 0.00024, Train Loss: 0.00860, Val Loss: 0.00840, Saved: 1\n",
      "Epoch: 95 ,LR: 0.00024, Train Loss: 0.00856, Val Loss: 0.00836, Saved: 1\n",
      "Epoch: 96 ,LR: 0.00024, Train Loss: 0.00860, Val Loss: 0.00840, Saved: 1\n",
      "Epoch: 97 ,LR: 0.00024, Train Loss: 0.00857, Val Loss: 0.00836, Saved: 1\n",
      "Epoch: 98 ,LR: 0.00024, Train Loss: 0.00857, Val Loss: 0.00837, Saved: 1\n",
      "Epoch: 99 ,LR: 0.00024, Train Loss: 0.00866, Val Loss: 0.00846, Saved: 1\n",
      "Epoch: 100 ,LR: 0.00023, Train Loss: 0.00864, Val Loss: 0.00844, Saved: 1\n",
      "Epoch: 101 ,LR: 0.00023, Train Loss: 0.00857, Val Loss: 0.00835, Saved: 1\n",
      "Epoch: 102 ,LR: 0.00023, Train Loss: 0.00857, Val Loss: 0.00835, Saved: 1\n",
      "Epoch: 103 ,LR: 0.00023, Train Loss: 0.00865, Val Loss: 0.00844, Saved: 1\n",
      "Epoch: 104 ,LR: 0.00023, Train Loss: 0.00895, Val Loss: 0.00877, Saved: 1\n",
      "Epoch: 105 ,LR: 0.00023, Train Loss: 0.00864, Val Loss: 0.00843, Saved: 1\n",
      "Epoch: 106 ,LR: 0.00023, Train Loss: 0.00866, Val Loss: 0.00845, Saved: 1\n",
      "Epoch: 107 ,LR: 0.00023, Train Loss: 0.00865, Val Loss: 0.00845, Saved: 1\n",
      "Epoch: 108 ,LR: 0.00023, Train Loss: 0.00856, Val Loss: 0.00834, Saved: 1\n",
      "Epoch: 109 ,LR: 0.00022, Train Loss: 0.00869, Val Loss: 0.00850, Saved: 1\n",
      "Epoch: 110 ,LR: 0.00022, Train Loss: 0.00856, Val Loss: 0.00836, Saved: 1\n",
      "Epoch: 111 ,LR: 0.00022, Train Loss: 0.00856, Val Loss: 0.00834, Saved: 1\n",
      "Epoch: 112 ,LR: 0.00022, Train Loss: 0.00855, Val Loss: 0.00834, Saved: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 113 ,LR: 0.00022, Train Loss: 0.00858, Val Loss: 0.00837, Saved: 1\n",
      "Epoch: 114 ,LR: 0.00022, Train Loss: 0.00873, Val Loss: 0.00855, Saved: 1\n",
      "Epoch: 115 ,LR: 0.00022, Train Loss: 0.00858, Val Loss: 0.00837, Saved: 1\n",
      "Epoch: 116 ,LR: 0.00022, Train Loss: 0.00854, Val Loss: 0.00833, Saved: 1\n",
      "Epoch: 117 ,LR: 0.00021, Train Loss: 0.00867, Val Loss: 0.00847, Saved: 1\n",
      "Epoch: 118 ,LR: 0.00021, Train Loss: 0.00853, Val Loss: 0.00833, Saved: 1\n",
      "Epoch: 119 ,LR: 0.00021, Train Loss: 0.00860, Val Loss: 0.00841, Saved: 1\n",
      "Epoch: 120 ,LR: 0.00021, Train Loss: 0.00854, Val Loss: 0.00833, Saved: 1\n",
      "Epoch: 121 ,LR: 0.00021, Train Loss: 0.00854, Val Loss: 0.00835, Saved: 1\n",
      "Epoch: 122 ,LR: 0.00021, Train Loss: 0.00855, Val Loss: 0.00835, Saved: 1\n",
      "Epoch: 123 ,LR: 0.00021, Train Loss: 0.00853, Val Loss: 0.00832, Saved: 1\n",
      "Epoch: 124 ,LR: 0.00021, Train Loss: 0.00860, Val Loss: 0.00839, Saved: 1\n",
      "Epoch: 125 ,LR: 0.00021, Train Loss: 0.00855, Val Loss: 0.00835, Saved: 1\n",
      "Epoch: 126 ,LR: 0.00020, Train Loss: 0.00852, Val Loss: 0.00831, Saved: 1\n",
      "Epoch: 127 ,LR: 0.00020, Train Loss: 0.00871, Val Loss: 0.00853, Saved: 1\n",
      "Epoch: 128 ,LR: 0.00020, Train Loss: 0.00858, Val Loss: 0.00838, Saved: 1\n",
      "Epoch: 129 ,LR: 0.00020, Train Loss: 0.00860, Val Loss: 0.00841, Saved: 1\n",
      "Epoch: 130 ,LR: 0.00020, Train Loss: 0.00856, Val Loss: 0.00836, Saved: 1\n",
      "Epoch: 131 ,LR: 0.00020, Train Loss: 0.00872, Val Loss: 0.00853, Saved: 1\n",
      "Epoch: 132 ,LR: 0.00020, Train Loss: 0.00863, Val Loss: 0.00844, Saved: 1\n",
      "Epoch: 133 ,LR: 0.00020, Train Loss: 0.00859, Val Loss: 0.00839, Saved: 1\n",
      "Epoch: 134 ,LR: 0.00019, Train Loss: 0.00852, Val Loss: 0.00832, Saved: 1\n",
      "Epoch: 135 ,LR: 0.00019, Train Loss: 0.00852, Val Loss: 0.00833, Saved: 1\n",
      "Epoch: 136 ,LR: 0.00019, Train Loss: 0.00858, Val Loss: 0.00838, Saved: 1\n",
      "Epoch: 137 ,LR: 0.00019, Train Loss: 0.00854, Val Loss: 0.00835, Saved: 1\n",
      "Epoch: 138 ,LR: 0.00019, Train Loss: 0.00854, Val Loss: 0.00834, Saved: 1\n",
      "Epoch: 139 ,LR: 0.00019, Train Loss: 0.00853, Val Loss: 0.00834, Saved: 1\n",
      "Epoch: 140 ,LR: 0.00019, Train Loss: 0.00851, Val Loss: 0.00831, Saved: 1\n",
      "Epoch: 141 ,LR: 0.00019, Train Loss: 0.00852, Val Loss: 0.00831, Saved: 1\n",
      "Epoch: 142 ,LR: 0.00019, Train Loss: 0.00852, Val Loss: 0.00831, Saved: 1\n",
      "Epoch: 143 ,LR: 0.00018, Train Loss: 0.00851, Val Loss: 0.00831, Saved: 1\n",
      "Epoch: 144 ,LR: 0.00018, Train Loss: 0.00858, Val Loss: 0.00840, Saved: 1\n",
      "Epoch: 145 ,LR: 0.00018, Train Loss: 0.00852, Val Loss: 0.00833, Saved: 1\n",
      "Epoch: 146 ,LR: 0.00018, Train Loss: 0.00852, Val Loss: 0.00831, Saved: 1\n",
      "Epoch: 147 ,LR: 0.00018, Train Loss: 0.00855, Val Loss: 0.00835, Saved: 1\n",
      "Epoch: 148 ,LR: 0.00018, Train Loss: 0.00854, Val Loss: 0.00834, Saved: 1\n",
      "Epoch: 149 ,LR: 0.00018, Train Loss: 0.00859, Val Loss: 0.00838, Saved: 1\n",
      "Epoch: 150 ,LR: 0.00018, Train Loss: 0.00851, Val Loss: 0.00831, Saved: 1\n",
      "Epoch: 151 ,LR: 0.00017, Train Loss: 0.00852, Val Loss: 0.00833, Saved: 1\n",
      "Epoch: 152 ,LR: 0.00017, Train Loss: 0.00850, Val Loss: 0.00830, Saved: 1\n",
      "Epoch: 153 ,LR: 0.00017, Train Loss: 0.00851, Val Loss: 0.00831, Saved: 1\n",
      "Epoch: 154 ,LR: 0.00017, Train Loss: 0.00860, Val Loss: 0.00841, Saved: 1\n",
      "Epoch: 155 ,LR: 0.00017, Train Loss: 0.00849, Val Loss: 0.00830, Saved: 1\n",
      "Epoch: 156 ,LR: 0.00017, Train Loss: 0.00848, Val Loss: 0.00828, Saved: 1\n",
      "Epoch: 157 ,LR: 0.00017, Train Loss: 0.00852, Val Loss: 0.00832, Saved: 1\n",
      "Epoch: 158 ,LR: 0.00017, Train Loss: 0.00856, Val Loss: 0.00837, Saved: 1\n",
      "Epoch: 159 ,LR: 0.00017, Train Loss: 0.00852, Val Loss: 0.00833, Saved: 1\n",
      "Epoch: 160 ,LR: 0.00016, Train Loss: 0.00850, Val Loss: 0.00830, Saved: 1\n",
      "Epoch: 161 ,LR: 0.00016, Train Loss: 0.00862, Val Loss: 0.00843, Saved: 1\n",
      "Epoch: 162 ,LR: 0.00016, Train Loss: 0.00849, Val Loss: 0.00830, Saved: 1\n",
      "Epoch: 163 ,LR: 0.00016, Train Loss: 0.00859, Val Loss: 0.00840, Saved: 1\n",
      "Epoch: 164 ,LR: 0.00016, Train Loss: 0.00849, Val Loss: 0.00829, Saved: 1\n",
      "Epoch: 165 ,LR: 0.00016, Train Loss: 0.00852, Val Loss: 0.00833, Saved: 1\n",
      "Epoch: 166 ,LR: 0.00016, Train Loss: 0.00850, Val Loss: 0.00830, Saved: 1\n",
      "Epoch: 167 ,LR: 0.00016, Train Loss: 0.00858, Val Loss: 0.00837, Saved: 1\n",
      "Epoch: 168 ,LR: 0.00016, Train Loss: 0.00851, Val Loss: 0.00831, Saved: 1\n",
      "Epoch: 169 ,LR: 0.00015, Train Loss: 0.00849, Val Loss: 0.00831, Saved: 1\n",
      "Epoch: 170 ,LR: 0.00015, Train Loss: 0.00848, Val Loss: 0.00827, Saved: 1\n",
      "Epoch: 171 ,LR: 0.00015, Train Loss: 0.00850, Val Loss: 0.00831, Saved: 1\n",
      "Epoch: 172 ,LR: 0.00015, Train Loss: 0.00847, Val Loss: 0.00827, Saved: 1\n",
      "Epoch: 173 ,LR: 0.00015, Train Loss: 0.00850, Val Loss: 0.00829, Saved: 1\n",
      "Epoch: 174 ,LR: 0.00015, Train Loss: 0.00846, Val Loss: 0.00827, Saved: 1\n",
      "Epoch: 175 ,LR: 0.00015, Train Loss: 0.00848, Val Loss: 0.00828, Saved: 1\n",
      "Epoch: 176 ,LR: 0.00015, Train Loss: 0.00847, Val Loss: 0.00828, Saved: 1\n",
      "Epoch: 177 ,LR: 0.00014, Train Loss: 0.00847, Val Loss: 0.00827, Saved: 1\n",
      "Epoch: 178 ,LR: 0.00014, Train Loss: 0.00861, Val Loss: 0.00841, Saved: 1\n",
      "Epoch: 179 ,LR: 0.00014, Train Loss: 0.00850, Val Loss: 0.00830, Saved: 1\n",
      "Epoch: 180 ,LR: 0.00014, Train Loss: 0.00848, Val Loss: 0.00829, Saved: 1\n",
      "Epoch: 181 ,LR: 0.00014, Train Loss: 0.00849, Val Loss: 0.00829, Saved: 1\n",
      "Epoch: 182 ,LR: 0.00014, Train Loss: 0.00847, Val Loss: 0.00826, Saved: 1\n",
      "Epoch: 183 ,LR: 0.00014, Train Loss: 0.00846, Val Loss: 0.00826, Saved: 1\n",
      "Epoch: 184 ,LR: 0.00014, Train Loss: 0.00853, Val Loss: 0.00833, Saved: 1\n",
      "Epoch: 185 ,LR: 0.00014, Train Loss: 0.00848, Val Loss: 0.00829, Saved: 1\n",
      "Epoch: 186 ,LR: 0.00013, Train Loss: 0.00849, Val Loss: 0.00829, Saved: 1\n",
      "Epoch: 187 ,LR: 0.00013, Train Loss: 0.00847, Val Loss: 0.00827, Saved: 1\n",
      "Epoch: 188 ,LR: 0.00013, Train Loss: 0.00845, Val Loss: 0.00825, Saved: 1\n",
      "Epoch: 189 ,LR: 0.00013, Train Loss: 0.00853, Val Loss: 0.00834, Saved: 1\n",
      "Epoch: 190 ,LR: 0.00013, Train Loss: 0.00860, Val Loss: 0.00841, Saved: 1\n",
      "Epoch: 191 ,LR: 0.00013, Train Loss: 0.00848, Val Loss: 0.00829, Saved: 1\n",
      "Epoch: 192 ,LR: 0.00013, Train Loss: 0.00845, Val Loss: 0.00825, Saved: 1\n",
      "Epoch: 193 ,LR: 0.00013, Train Loss: 0.00845, Val Loss: 0.00825, Saved: 1\n",
      "Epoch: 194 ,LR: 0.00012, Train Loss: 0.00846, Val Loss: 0.00827, Saved: 1\n",
      "Epoch: 195 ,LR: 0.00012, Train Loss: 0.00846, Val Loss: 0.00827, Saved: 1\n",
      "Epoch: 196 ,LR: 0.00012, Train Loss: 0.00844, Val Loss: 0.00824, Saved: 1\n",
      "Epoch: 197 ,LR: 0.00012, Train Loss: 0.00845, Val Loss: 0.00825, Saved: 1\n",
      "Epoch: 198 ,LR: 0.00012, Train Loss: 0.00844, Val Loss: 0.00825, Saved: 1\n",
      "Epoch: 199 ,LR: 0.00012, Train Loss: 0.00845, Val Loss: 0.00825, Saved: 1\n",
      "Epoch: 200 ,LR: 0.00012, Train Loss: 0.00846, Val Loss: 0.00828, Saved: 1\n",
      "Epoch: 201 ,LR: 0.00012, Train Loss: 0.00850, Val Loss: 0.00831, Saved: 1\n",
      "Epoch: 202 ,LR: 0.00012, Train Loss: 0.00848, Val Loss: 0.00828, Saved: 1\n",
      "Epoch: 203 ,LR: 0.00011, Train Loss: 0.00844, Val Loss: 0.00824, Saved: 1\n",
      "Epoch: 204 ,LR: 0.00011, Train Loss: 0.00851, Val Loss: 0.00830, Saved: 1\n",
      "Epoch: 205 ,LR: 0.00011, Train Loss: 0.00845, Val Loss: 0.00827, Saved: 1\n",
      "Epoch: 206 ,LR: 0.00011, Train Loss: 0.00843, Val Loss: 0.00825, Saved: 1\n",
      "Epoch: 207 ,LR: 0.00011, Train Loss: 0.00845, Val Loss: 0.00826, Saved: 1\n",
      "Epoch: 208 ,LR: 0.00011, Train Loss: 0.00848, Val Loss: 0.00829, Saved: 1\n",
      "Epoch: 209 ,LR: 0.00011, Train Loss: 0.00844, Val Loss: 0.00826, Saved: 1\n",
      "Epoch: 210 ,LR: 0.00011, Train Loss: 0.00848, Val Loss: 0.00828, Saved: 1\n",
      "Epoch: 211 ,LR: 0.00011, Train Loss: 0.00844, Val Loss: 0.00826, Saved: 1\n",
      "Epoch: 212 ,LR: 0.00010, Train Loss: 0.00845, Val Loss: 0.00828, Saved: 1\n",
      "Epoch: 213 ,LR: 0.00010, Train Loss: 0.00845, Val Loss: 0.00827, Saved: 1\n",
      "Epoch: 214 ,LR: 0.00010, Train Loss: 0.00845, Val Loss: 0.00826, Saved: 1\n",
      "Epoch: 215 ,LR: 0.00010, Train Loss: 0.00844, Val Loss: 0.00826, Saved: 1\n",
      "Epoch: 216 ,LR: 0.00010, Train Loss: 0.00847, Val Loss: 0.00828, Saved: 1\n",
      "Epoch: 217 ,LR: 0.00010, Train Loss: 0.00848, Val Loss: 0.00830, Saved: 1\n",
      "Epoch: 218 ,LR: 0.00010, Train Loss: 0.00850, Val Loss: 0.00832, Saved: 1\n",
      "Epoch: 219 ,LR: 0.00010, Train Loss: 0.00845, Val Loss: 0.00827, Saved: 1\n",
      "Epoch: 220 ,LR: 0.00009, Train Loss: 0.00843, Val Loss: 0.00825, Saved: 1\n",
      "Epoch: 221 ,LR: 0.00009, Train Loss: 0.00844, Val Loss: 0.00824, Saved: 1\n",
      "Epoch: 222 ,LR: 0.00009, Train Loss: 0.00859, Val Loss: 0.00841, Saved: 1\n",
      "Epoch: 223 ,LR: 0.00009, Train Loss: 0.00846, Val Loss: 0.00827, Saved: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 224 ,LR: 0.00009, Train Loss: 0.00843, Val Loss: 0.00824, Saved: 1\n",
      "Epoch: 225 ,LR: 0.00009, Train Loss: 0.00845, Val Loss: 0.00827, Saved: 1\n",
      "Epoch: 226 ,LR: 0.00009, Train Loss: 0.00852, Val Loss: 0.00834, Saved: 1\n",
      "Epoch: 227 ,LR: 0.00009, Train Loss: 0.00841, Val Loss: 0.00823, Saved: 1\n",
      "Epoch: 228 ,LR: 0.00009, Train Loss: 0.00842, Val Loss: 0.00824, Saved: 1\n",
      "Epoch: 229 ,LR: 0.00008, Train Loss: 0.00849, Val Loss: 0.00831, Saved: 1\n",
      "Epoch: 230 ,LR: 0.00008, Train Loss: 0.00845, Val Loss: 0.00826, Saved: 1\n",
      "Epoch: 231 ,LR: 0.00008, Train Loss: 0.00845, Val Loss: 0.00825, Saved: 1\n",
      "Epoch: 232 ,LR: 0.00008, Train Loss: 0.00844, Val Loss: 0.00824, Saved: 1\n",
      "Epoch: 233 ,LR: 0.00008, Train Loss: 0.00845, Val Loss: 0.00826, Saved: 1\n",
      "Epoch: 234 ,LR: 0.00008, Train Loss: 0.00843, Val Loss: 0.00825, Saved: 1\n",
      "Epoch: 235 ,LR: 0.00008, Train Loss: 0.00843, Val Loss: 0.00824, Saved: 1\n",
      "Epoch: 236 ,LR: 0.00008, Train Loss: 0.00842, Val Loss: 0.00823, Saved: 1\n",
      "Epoch: 237 ,LR: 0.00007, Train Loss: 0.00844, Val Loss: 0.00827, Saved: 1\n",
      "Epoch: 238 ,LR: 0.00007, Train Loss: 0.00843, Val Loss: 0.00823, Saved: 1\n",
      "Epoch: 239 ,LR: 0.00007, Train Loss: 0.00844, Val Loss: 0.00825, Saved: 1\n",
      "Epoch: 240 ,LR: 0.00007, Train Loss: 0.00843, Val Loss: 0.00824, Saved: 1\n",
      "Epoch: 241 ,LR: 0.00007, Train Loss: 0.00842, Val Loss: 0.00823, Saved: 1\n",
      "Epoch: 242 ,LR: 0.00007, Train Loss: 0.00842, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 243 ,LR: 0.00007, Train Loss: 0.00840, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 244 ,LR: 0.00007, Train Loss: 0.00843, Val Loss: 0.00824, Saved: 1\n",
      "Epoch: 245 ,LR: 0.00007, Train Loss: 0.00842, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 246 ,LR: 0.00006, Train Loss: 0.00842, Val Loss: 0.00823, Saved: 1\n",
      "Epoch: 247 ,LR: 0.00006, Train Loss: 0.00843, Val Loss: 0.00826, Saved: 1\n",
      "Epoch: 248 ,LR: 0.00006, Train Loss: 0.00841, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 249 ,LR: 0.00006, Train Loss: 0.00842, Val Loss: 0.00823, Saved: 1\n",
      "Epoch: 250 ,LR: 0.00006, Train Loss: 0.00841, Val Loss: 0.00824, Saved: 1\n",
      "Epoch: 251 ,LR: 0.00006, Train Loss: 0.00841, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 252 ,LR: 0.00006, Train Loss: 0.00841, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 253 ,LR: 0.00006, Train Loss: 0.00840, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 254 ,LR: 0.00005, Train Loss: 0.00840, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 255 ,LR: 0.00005, Train Loss: 0.00841, Val Loss: 0.00823, Saved: 1\n",
      "Epoch: 256 ,LR: 0.00005, Train Loss: 0.00840, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 257 ,LR: 0.00005, Train Loss: 0.00840, Val Loss: 0.00823, Saved: 1\n",
      "Epoch: 258 ,LR: 0.00005, Train Loss: 0.00842, Val Loss: 0.00825, Saved: 1\n",
      "Epoch: 259 ,LR: 0.00005, Train Loss: 0.00842, Val Loss: 0.00824, Saved: 1\n",
      "Epoch: 260 ,LR: 0.00005, Train Loss: 0.00842, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 261 ,LR: 0.00005, Train Loss: 0.00840, Val Loss: 0.00823, Saved: 1\n",
      "Epoch: 262 ,LR: 0.00005, Train Loss: 0.00839, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 263 ,LR: 0.00004, Train Loss: 0.00842, Val Loss: 0.00823, Saved: 1\n",
      "Epoch: 264 ,LR: 0.00004, Train Loss: 0.00841, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 265 ,LR: 0.00004, Train Loss: 0.00840, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 266 ,LR: 0.00004, Train Loss: 0.00841, Val Loss: 0.00823, Saved: 1\n",
      "Epoch: 267 ,LR: 0.00004, Train Loss: 0.00840, Val Loss: 0.00823, Saved: 1\n",
      "Epoch: 268 ,LR: 0.00004, Train Loss: 0.00840, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 269 ,LR: 0.00004, Train Loss: 0.00840, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 270 ,LR: 0.00004, Train Loss: 0.00840, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 271 ,LR: 0.00004, Train Loss: 0.00840, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 272 ,LR: 0.00003, Train Loss: 0.00840, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 273 ,LR: 0.00003, Train Loss: 0.00840, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 274 ,LR: 0.00003, Train Loss: 0.00840, Val Loss: 0.00820, Saved: 1\n",
      "Epoch: 275 ,LR: 0.00003, Train Loss: 0.00840, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 276 ,LR: 0.00003, Train Loss: 0.00840, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 277 ,LR: 0.00003, Train Loss: 0.00839, Val Loss: 0.00820, Saved: 1\n",
      "Epoch: 278 ,LR: 0.00003, Train Loss: 0.00841, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 279 ,LR: 0.00003, Train Loss: 0.00839, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 280 ,LR: 0.00002, Train Loss: 0.00839, Val Loss: 0.00822, Saved: 1\n",
      "Epoch: 281 ,LR: 0.00002, Train Loss: 0.00839, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 282 ,LR: 0.00002, Train Loss: 0.00840, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 283 ,LR: 0.00002, Train Loss: 0.00840, Val Loss: 0.00820, Saved: 1\n",
      "Epoch: 284 ,LR: 0.00002, Train Loss: 0.00839, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 285 ,LR: 0.00002, Train Loss: 0.00838, Val Loss: 0.00820, Saved: 1\n",
      "Epoch: 286 ,LR: 0.00002, Train Loss: 0.00839, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 287 ,LR: 0.00002, Train Loss: 0.00838, Val Loss: 0.00820, Saved: 1\n",
      "Epoch: 288 ,LR: 0.00002, Train Loss: 0.00838, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 289 ,LR: 0.00001, Train Loss: 0.00838, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 290 ,LR: 0.00001, Train Loss: 0.00839, Val Loss: 0.00819, Saved: 1\n",
      "Epoch: 291 ,LR: 0.00001, Train Loss: 0.00838, Val Loss: 0.00820, Saved: 1\n",
      "Epoch: 292 ,LR: 0.00001, Train Loss: 0.00838, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 293 ,LR: 0.00001, Train Loss: 0.00839, Val Loss: 0.00820, Saved: 1\n",
      "Epoch: 294 ,LR: 0.00001, Train Loss: 0.00839, Val Loss: 0.00820, Saved: 1\n",
      "Epoch: 295 ,LR: 0.00001, Train Loss: 0.00837, Val Loss: 0.00821, Saved: 1\n",
      "Epoch: 296 ,LR: 0.00001, Train Loss: 0.00839, Val Loss: 0.00820, Saved: 1\n",
      "Epoch: 297 ,LR: 0.00000, Train Loss: 0.00839, Val Loss: 0.00820, Saved: 1\n",
      "Epoch: 298 ,LR: 0.00000, Train Loss: 0.00838, Val Loss: 0.00820, Saved: 1\n",
      "Epoch: 299 ,LR: 0.00000, Train Loss: 0.00839, Val Loss: 0.00821, Saved: 1\n"
     ]
    }
   ],
   "source": [
    "from scripts.training import trainingLoop\n",
    "\n",
    "from CNNs.SUM import SUM_2d\n",
    "cnn = SUM_2d(in_chans, depth, wf).float().cuda()\n",
    "\n",
    "##############\n",
    "# Epoch loop #\n",
    "trainingLoop(\n",
    "    cnn,\n",
    "    trai_data,\n",
    "    vali_data,\n",
    "    epo, bs,\n",
    "    loss_trai,\n",
    "    loss_vali,\n",
    "    torch.optim.AdamW(cnn.parameters(), lr=ilr, weight_decay=0.25),\n",
    "    ilr,\n",
    "    \"./CNN_weights/SUM_DENO.pyt\",\n",
    "    printLog=True,\n",
    "    logName=\"./CNN_weights/logs/SUM_DENO.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_1p4_astralocal)",
   "language": "python",
   "name": "pytorch_1p4_astralocal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
